<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux 下数据无损动态修改硬盘MBR分区表为GPT]]></title>
    <url>%2F2019%2F04%2F04%2FLinux-%E4%B8%8B%E6%95%B0%E6%8D%AE%E6%97%A0%E6%8D%9F%E5%8A%A8%E6%80%81%E4%BF%AE%E6%94%B9%E7%A1%AC%E7%9B%98MBR%E5%88%86%E5%8C%BA%E8%A1%A8%E4%B8%BAGPT%2F</url>
    <content type="text"><![CDATA[1.简介 腾讯云官网中有一篇帮助文档“扩容Linux文件系统，https://www.qcloud.com/document/product/362/6738，讲解了GPT分区云硬盘扩容后修改分区指引和MBR分区云硬盘扩容后修改分区指引。其中MBR分区扩容下，若扩容后的空间已经大于2TB则不可选择。官网文档没有涉及到MBR的分区扩展到2T以上该怎么处理。 注：写在文前。不管任何形式的扩容硬盘，最好都事先做好硬盘数据的快照，避免手误或者其他因素造成数据丢失。数据无价！！！ 2.下面讲解数据无损动态调整MBR的分区为GPT（1）fdisk -l /dev/vdb &amp;&amp; partprobe -s （2）下面以/dev/vdc这块盘做讲解，新建了一个/dev/vdc1分区，并且格式化为ext3文件系统。 fdsik -l /dev/vdc &amp;&amp; mkfs.ext3 /dev/vdc1 （3）下面我在控制台把/dev/vdc这块硬盘扩容到2T以上，并且重新挂载。 （4）接下来看一下，在MBR分区表下，扩容/dev/vdc1到2.5T能不能行？ 这里看到只能扩容到2TB。gg （5）显然这是MBR分区表的局限。MBR分区表共512个字节。前446字节包括boot loader信息和grub引导信息，还有64字节的磁盘分区信息，以及2个字节的结束标志。而每个主分区要在分区表里占用16字节。所以单个硬盘只能分64/16个主分区。至于为什么每个分区不能超过2TB，请看下图。 （6）接下来说一下我这个数据无损在线动态调整MBR为GPT方法吧。注：不管是怎么扩容硬盘，扩容前都建议对云硬盘做一下快照。 A.为了证明数据真的无损，我们新建几个file。最后再来看一下数据情况。 B.卸载/dev/vdc1 C.用gdisk(安装方法:yum install gdisk)把MBR分区格式转换程GPT分区格式(MBR不支持2T以上大小) 注：这个方法在大部分场景下都是可以转mbr为gpt的，只有磁盘开头前33个扇区，或最后34个扇区被分区占用的场景不支持。我们的硬盘分区时，默认是从2048扇区开始分的，所以一般不会出现前34个扇区被占用，客户控制台扩容实体云硬盘之后，后33扇区也不存在被占用。所以绝大多数情况下前34后33分区都不会被占用。除非客户主动刻意去占用。这里可以通过part ed 硬盘–unit s–p查看硬盘前34分区有没有被占用。 D.使用parted删除vdc1，并重新创建vdc1(fdisk不支持超过2TB大小，注意记住删除前vdc1的start sector，创建新的vdc1的时候start sector必须和删除前一致) E.目前还需要扩展下分区，才能挂载正常显示分区大小。 注：这里也可能会遇到下面这种情况 ‘’’ [root@bobo ~]# e2fsck -yf /dev/vdc1 e2fsck 1.42.9 (28-Dec-2013) The filesystem size (according to the superblock) is xxx blocks The physical size of the device is xxx blocks Either the superblock or the partition table is likely to be corrupt! Abort? yes ‘’’ 这里是检测到分区表变化了，询问是否放弃修复，并不是报错。这里我加y这个参数的原因在于，如果出现错误直接fix。如果遇到了这种情况，可以直接用这个命令e2fsck -f /dev/vdb1直接修复分区就ok。 F.重新挂载下看下分区大小,并检查下数据完整性 3.GPT分区的优越性（GUID partition table, GPT 磁盘分区表。）1因为过去一个扇区大小就是 512Bytes 而已，不过目前已经有 4K 的扇区设计出现！为了相容于所有的磁盘，因此在扇区的定义上面， 大多会使用所谓的逻辑区块位址（Logical Block Address, LBA）来处理。GPT 将磁盘所有区块以此 LBA（默认为 512Bytes ！） 来规划，而第一个 LBA 称为 LBA0 （从 0 开始编号）。与 MBR 仅使用第一个 512Bytes 区块来纪录不同， GPT 使用了 34 个 LBA 区块来纪录分区信息！同时与过去 MBR 仅有一的区块，被干掉就死光光的情况不同， GPT 除了前面 34 个 LBA 之外，整个磁盘的最后 33 个 LBA 也拿来作为另一个备份！这样或许会比较安全些吧！ 结构详解： LBA0：和传统MBR分区一样，仍然为主引导记录 LBA1：我们称之为“主分区头” LBA2-33：共计32个扇区，我们称之为“主分区节点” LBA-1：我们称之为“备份分区头”，它就是“主分区头”的一个Copy LBA-2-33：共计32个扇区，我们称之为“备份分区节点”，它就是“主分区节点”的一个Copy LBA34：正常的GPT分区内容，文件系统（如：FAT，NTFS，EXT等）就是构建在这里面。 大概了解一下:LBA2-LBA33 4.常用的分区处理的工具（1）fdisk(MBR) （2）gdisk(GPT) （3）parted（MBR和GPT通用） 注:gdisk和fdisk最好不要混用，不要用fdsik处理gpt分区，也不要用gdisk处理mbr分区，一不小心，数据搞没了，后悔都来不及。 云+社区链接：https://cloud.tencent.com/developer/article/1175328]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>MBR</tag>
        <tag>GPT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7 升级系统内核]]></title>
    <url>%2F2019%2F02%2F28%2FCentos7-%E5%8D%87%E7%BA%A7%E7%B3%BB%E7%BB%9F%E5%86%85%E6%A0%B8%2F</url>
    <content type="text"><![CDATA[Centos7 升级系统内核 安装yum源 12rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgrpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm 查看列表 12yum --disablerepo=* --enablerepo=elrepo-kernel repolistyum --disablerepo=* --enablerepo=elrepo-kernel list kernel* 安装最新版本的kernel 1yum --enablerepo=elrepo-kernel install kernel-ml-devel kernel-ml -y 设置为默认内核 12345[root@localhost ~]# awk -F\&apos; &apos;$1==&quot;menuentry &quot; &#123;print $2&#125;&apos; /etc/grub2.cfgCentOS Linux (4.20.13-1.el7.elrepo.x86_64) 7 (Core)CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core)CentOS Linux (0-rescue-54dbc7f0d8ee49babd50ed6f840123fa) 7 (Core)当前默认内核为1 12345678910[root@localhost ~]# vim /etc/default/grub GRUB_TIMEOUT=5GRUB_DISTRIBUTOR=&quot;$(sed &apos;s, release .*$,,g&apos; /etc/system-release)&quot;GRUB_DEFAULT=0GRUB_DISABLE_SUBMENU=trueGRUB_TERMINAL_OUTPUT=&quot;console&quot;GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet&quot;GRUB_DISABLE_RECOVERY=&quot;true&quot;GRUB_DEFAULT=saved 改成 GRUB_DEFAULT=0 12[root@localhost ~]# grub2-mkconfig -o /boot/grub2/grub.cfg生成新配置文件 重启系统查看内核 123[root@localhost ~]# reboot[root@localhost ~]# uname -r4.20.13-1.el7.elrepo.x86_64]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KVM虚拟化技术之使用Qemu-kvm创建和管理虚拟机]]></title>
    <url>%2F2019%2F02%2F27%2FKVM%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E4%B9%8B%E4%BD%BF%E7%94%A8Qemu-kvm%E5%88%9B%E5%BB%BA%E5%92%8C%E7%AE%A1%E7%90%86%E8%99%9A%E6%8B%9F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[KVM虚拟化技术之使用Qemu-kvm创建和管理虚拟机 KVM介绍 KVM是开源软件，全称是kernel-based virtual machine（基于内核的虚拟机），属于内核的一个模块，Linux 2.6.20核心以上的版本中默认带有kvm模块。它包含一个为处理器提供底层虚拟化 可加载的核心模块kvm.ko（kvm-intel.ko或kvm-AMD.ko） kvm虚拟机=kvm模块 + qemu模拟器 kvm负责分配内存和cpu，qemu负责模拟网络设备和io设备 系统初始化 检查服务器是否支持虚拟化 1[root@kvm ~]# egrep &apos;(vmx|svm)&apos; /proc/cpuinfo 检查内核中是否加载kvm模块 1234[root@kvm ~]# lsmod | grep kvmkvm_intel 174841 3 kvm 578518 1 kvm_intelirqbypass 13503 3 kvm 关闭selinux 12345[root@kvm ~]# cat /etc/sysconfig/selinux | grep &quot;SELINUX&quot;# SELINUX= can take one of these three values:SELINUX=disabled# SELINUXTYPE= can take one of three two values:SELINUXTYPE=targeted 为KVM虚拟机配置桥接网络 新建网桥br0，并配置，转移ip到网桥上 1234567891011[root@kvm ~]# cd /etc/sysconfig/network-scripts/[root@kvm network-scripts]# cat ifcfg-br0 TYPE=BridgeBOOTPROTO=noneDEFROUTE=yesNAME=br0DEVICE=br0ONBOOT=yesIPADDR=192.168.175.6PREFIX=24GATEWAY=192.168.175.2 配置eth0使用桥接模式 1234567[root@kvm network-scripts]# cat ifcfg-eth0 TYPE=EthernetBOOTPROTO=noneNAME=eth0DEVICE=eth0ONBOOT=yesBRIDGE=br0 配置完成后，重启网络服务 1[root@kvm network-scripts]# systemctl restart network 查看ifconfig如下 1234567891011121314151617[root@kvm network-scripts]# ifconfig br0br0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.175.6 netmask 255.255.255.0 broadcast 192.168.175.255 inet6 fe80::20c:29ff:fe52:20f6 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:52:20:f6 txqueuelen 1000 (Ethernet) RX packets 49 bytes 4628 (4.5 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 53 bytes 7133 (6.9 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0[root@kvm network-scripts]# ifconfig eth0eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 ether 00:0c:29:52:20:f6 txqueuelen 1000 (Ethernet) RX packets 6382 bytes 469272 (458.2 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 8765 bytes 703077 (686.5 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 安装kvm相关组件 安装命令 1[root@kvm network-scripts]# yum install qemu-kvm python-virtinst virt-* libvirt libvirt-client bridge-utils qemu-img -y 各组件功能 kvm模块：qemu-kvm 图形界面管理虚拟机：virt-manager 网络接口管理工具：bridge-utils 虚拟机管理工具：libvirt 虚拟机管理工具客户端：libivirt-client python组件，记录xml信息：python-virtinst qemu组件,创建硬盘，启动虚拟机等：qemu-img 虚拟机安装命令：virt-install 启动libvirt服务 1[root@kvm network-scripts]# systemctl start libvirtd &amp;&amp; systemctl enable libvirtd &amp;&amp; systemctl status libvirt 查看系统网络，会自动生成一个桥设备，默认虚拟机和宿主机通信的设备 123456789101112[root@kvm network-scripts]# ifconfig virbr0virbr0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500 inet 192.168.122.1 netmask 255.255.255.0 broadcast 192.168.122.255 ether 52:54:00:66:6f:6a txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0[root@kvm network-scripts]# brctl showbridge name bridge id STP enabled interfacesbr0 8000.000c295220f6 no eth0virbr0 8000.525400666f6a yes virbr0-nic 安装虚拟机 创建硬盘设备 1qemu-img create -f qcow2 /data/vm1.qcow2 5G 创建虚拟机 12virt-install --virt-type kvm --name vm2 --ram 512 --cdrom=/data/CentOS-7.5-x86_64-DVD-1804.iso --disk path=/data/vm1.qcow2 --network bridge=br0 --graphics vnc,listen=0.0.0.0 --noautoconsole注：自行上传iso系统镜像 安装tigervnc或者vnc viewe工具可以连接到安装虚拟机图形界面，默认端口5900 查看kvm进程 1234[root@kvm ~]# ps -ef | grep kvmroot 628 2 0 22:02 ? 00:00:00 [kvm-irqfd-clean]avahi 714 1 0 22:02 ? 00:00:00 avahi-daemon: running [kvm.local]qemu 3070 1 3 22:21 ? 00:01:26 /usr/libexec/qemu-kvm -name vm2 -S -machine pc-i440fx-rhel7.0.0,accelkvm,usb=off,dump-guest-core=off -cpu IvyBridge-IBRS -m 512 -realtime mlock=off -smp 1,sockets=1,cores=1,threads=1 -uuid ef1dcbd8-1684-4ae0-9dc7-500d59236911 -no-user-config -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/domain-2-vm2/monitor.sock,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc,driftfix=slew -global kvm-pit.lost_tick_policy=delay -no-hpet -no-shutdown -global PIIX4_PM.disable_s3=1 -global PIIX4_PM.disable_s4=1 -boot strict=on -device ich9-usb-ehci1,id=usb,bus=pci.0,addr=0x4.0x7 -device ich9-usb-uhci1,masterbus=usb.0,firstport=0,bus=pci.0,multifunction=on,addr=0x4 -device ich9-usb-uhci2,masterbus=usb.0,firstport=2,bus=pci.0,addr=0x4.0x1 -device ich9-usb-uhci3,masterbus=usb.0,firstport=4,bus=pci.0,addr=0x4.0x2 -device virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x5 -drive file=/data/vm1.qcow2,format=qcow2,if=none,id=drive-virtio-disk0 -device virtio-blk-pci,scsi=off,bus=pci.0,addr=0x6,drive=drive-virtio-disk0,id=virtio-disk0,bootindex=1 -drive if=none,id=drive-ide0-0-0,readonly=on -device ide-cd,bus=ide.0,unit=0,drive=drive-ide0-0-0,id=ide0-0-0 -netdev tap,fd=26,id=hostnet0,vhost=on,vhostfd=28 -device virtio-net-pci,netdev=hostnet0,id=net0,mac=52:54:00:0f:1f:00,bus=pci.0,addr=0x3 -chardev pty,id=charserial0 -device isa-serial,chardev=charserial0,id=serial0 -chardev socket,id=charchannel0,path=/var/lib/libvirt/qemu/channel/target/domain-2-vm2/org.qemu.guest_agent.0,server,nowait -device virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0 -device usb-tablet,id=input0,bus=usb.0,port=1 -vnc 0.0.0.0:0 -vga cirrus -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x7 -msg timestamp=on 实际上一个虚拟机对于宿主机而言，只是宿主机上的一个进程而已 查看虚拟机 1234[root@kvm ~]# virsh list Id Name State---------------------------------------------------- 2 vm2 running virsh常用命令 1234567virsh list --all ##列出所有虚拟机virsh list ##列出运行中的虚拟机virsh start vm ##启动虚拟机virsh shutdown vm ##关闭虚拟机virsh undfine vm ##销毁虚拟机virsh console vm1 ##通过console连接虚拟机virsh edit vm1 ##编辑位于/etc/libvirt/qemu/vm1.xml]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>kvm</tag>
        <tag>qemu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F02%2F26%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
